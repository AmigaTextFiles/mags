{backimage bg.iff}
{center}
{subhead}GetAllHTML{def}{p}
Review by Alan Crandall
{left}
{pp}
Have you ever visited a cool web site & wanted to keep a copy of some/all
of it, but it would takes ages to find & download all the respective pages/files?
This is the answer!
{pp}
You supply this ARexx script with the start page URL, and a destination
directory (which should be empty), and maybe a few other options - and off
it goes!  Note that it needs HTTPResume v1.3+ to work (get from Aminet).
{pp}
A most have for people who want to save complete web pages without the
hassle!
{pp}
Requires: HTTPResume v1.3+, Rexxsupport.library, ARexx
{pp}
{bold}Available from{nobold}: Aminet:comm/tcp/GetAllHTML.LHA ({link ftp://de.aminet.net/pub/aminet/comm/tcp/GetAllHTML.lha}Download This{end})
{pp}
{bold}Overall{nobold}: 86%
{pp}