<HTML>
<HEAD>
<TITLE>
GetAllHTML
</TITLE>
<meta http-equiv="content-type" content="text/html; charset=windows-1251">
<BODY BACKGROUND="../GFX/fonm.gif">
</HEAD>
<CENTER>
<H2><IMG SRC="../GFX/edu.gif"><FONT COLOR="yellow"><b>GetAllHTML</b></FONT><IMG SRC="../GFX/edu.gif"></H2><BR>

<table border="1" cellpadding="4" cellspacing="0" width="80%" bordercolorlight="#5091F3" bordercolordark="#000000">
<tr bgcolor="black"><td align="left" background="../GFX/fon.gif">
<table border="0" width="100%"><tr bgcolor="black">
<td align="right"><FONT COLOR="green">Автор -=\AmiF1Team/=-</FONT></td>
</tr></table>
</td></tr>
<tr bgcolor="black">
<td background="../GFX/fon.gif">
<b><FONT COLOR="white">Предположим,  занимаясь  серфингом  в  интернете,  вы  наткнулись  на сайт,
который  очень  вас  заинтересовал  и, как следствие, вы хотите его скачать
полностью.   Что же делать, не отгружать же каждую страничку в отдельности?
Естественно  нет.  GetAllHTML - и есть выход из данной проблемы.  Программа
представляет  собой  ARexx-скрипт,  для  пользования  которым  надо  просто
сообщить URL и директорию назначения - и дело в шляпе.  Всё просто.<P>
Скрипт требует наличия:  HTTPResume v1.3 и выше, Rexxsupport.library, ARexx.<P>
<CENTER>Утилита доступна на Аминете: <a href="ftp://de.aminet.net/pub/aminet/comm/tcp/GetAllHTML.lha"><FONT COLoR="green">GetAllHTML</FONT></a></CENTER></b></FONT>
</td></tr>
</table>
</td>
</tr>
</table><br>

</CENTER>
</BODY>
</HTML>